{
    "absolute_path_to_file_in_container": "/sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java",
    "errors": [
        {
            "line_number": 289,
            "message": "[ERROR] /sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java:[289,24] incompatible types: no instance(s) of type variable(s) T,V exist so that io.lettuce.core.Value<V> conforms to io.lettuce.core.ScoredValue<byte[]>",
            "additional_info": "",
            "file_name": "LettuceAnomalyReportAccessor.java",
            "uid": "18809662-a82d-578a-a742-32a7717c8fc9"
        },
        {
            "line_number": 291,
            "message": "[ERROR] /sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java:[291,26] incompatible types: no instance(s) of type variable(s) T,V exist so that io.lettuce.core.Value<V> conforms to io.lettuce.core.ScoredValue<byte[]>",
            "additional_info": "",
            "file_name": "LettuceAnomalyReportAccessor.java",
            "uid": "18809662-a82d-578a-a742-32a7717c8fc9"
        }
    ],
    "prompt": "Act as an Automatic Program Repair (APR) tool, reply only with code, without explanation. \nYou are specialized in breaking dependency updates, in which the failure is caused by an external dependency. \nTo solve the failure you can only work on the client code.\n\nAPI upgrade: lettuce-core 5.1.6.RELEASE->6.5.1.RELEASE\n\nthe following client code fails: \n'''java\npackage com.yahoo.sherlock.store.redis;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ExecutionException;\nimport com.beust.jcommander.internal.Lists;\nimport com.yahoo.sherlock.model.AnomalyReport;\nimport com.yahoo.sherlock.settings.Constants;\nimport com.yahoo.sherlock.settings.DatabaseConstants;\nimport com.yahoo.sherlock.store.AnomalyReportAccessor;\nimport com.yahoo.sherlock.store.StoreParams;\nimport com.yahoo.sherlock.store.core.AsyncCommands;\nimport com.yahoo.sherlock.store.core.RedisConnection;\nimport com.yahoo.sherlock.utils.NumberUtils;\nimport io.lettuce.core.RedisFuture;\nimport io.lettuce.core.ScoredValue;\nimport lombok.extern.slf4j.Slf4j;\nimport static com.yahoo.sherlock.store.redis.Mapper.encode;\n@Slf4j\npublic class LettuceAnomalyReportAccessor extends AbstractLettuceAccessor implements AnomalyReportAccessor {\n    private final String jobIdName;\n\n    private final String timeName;\n\n    private final String frequencyName;\n\n    private final String emailIdReportName;\n\n    public LettuceAnomalyReportAccessor(StoreParams params) {\n        super(params);\n        this.jobIdName = params.get(DatabaseConstants.INDEX_REPORT_JOB_ID);\n        this.timeName = params.get(DatabaseConstants.INDEX_TIMESTAMP);\n        this.frequencyName = params.get(DatabaseConstants.INDEX_FREQUENCY);\n        this.emailIdReportName = params.get(DatabaseConstants.INDEX_EMAILID_REPORT);\n    }\n\n    protected static boolean isMissingId(AnomalyReport report) {\n        return (report.getUniqueId() == null) || report.getUniqueId().isEmpty();\n    }\n\n    @Override\n    public void putAnomalyReports(List<AnomalyReport> reports, List<String> emailIds) throws IOException {\n        log.info(\"Putting [{}] anomaly reports\", reports.size());\n        try (RedisConnection<String> conn = connect();RedisConnection<byte[]> binary = binary()) {\n            List<AnomalyReport> requireId = new ArrayList<>(reports.size());\n            List<AnomalyReport> ready = new ArrayList<>(reports.size());\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            for (AnomalyReport report : reports) {\n                if (isMissingId(report)) {\n                    requireId.add(report);\n                } else {\n                    ready.add(report);\n                }\n            }\n            if (!requireId.isEmpty()) {\n                log.info(\"Generating new IDs for [{}] reports\", requireId.size());\n                Integer[] newIds = newIds(requireId.size());\n                for (int i = 0; i < newIds.length; i++) {\n                    requireId.get(i).setUniqueId(newIds[i].toString());\n                }\n                ready.addAll(requireId);\n                requireId.clear();\n            }\n            List<RedisFuture> arrFutures = new ArrayList<>(ready.size() + 1);\n            RedisFuture[] saddFutures = new RedisFuture[ready.size() * (6 + (2 * emailIds.size()))];\n            int i = 0;\n            long expirationTime = Constants.SECONDS_IN_DAY * (ready.get(0).getJobFrequency().equalsIgnoreCase(Constants.HOUR) ? Constants.REDIS_RETENTION_WEEKS_IN_DAYS : ready.get(0).getJobFrequency().equalsIgnoreCase(Constants.MINUTE) ? Constants.REDIS_RETENTION_ONE_DAY : Constants.REDIS_RETENTION_YEARS_IN_DAYS);\n            for (AnomalyReport report : ready) {\n                arrFutures.addAll(writeReport(bin, cmd, report, expirationTime, this));\n                saddFutures[i++] = cmd.sadd(index(jobIdName, report.getJobId()), report.getUniqueId());\n                saddFutures[i++] = cmd.expire(index(jobIdName, report.getJobId()), expirationTime);\n                saddFutures[i++] = cmd.sadd(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                saddFutures[i++] = cmd.expire(index(frequencyName, report.getJobFrequency()), expirationTime);\n                saddFutures[i++] = cmd.sadd(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                saddFutures[i++] = cmd.expire(index(timeName, report.getReportQueryEndTime()), expirationTime);\n                for (String emailId : emailIds) {\n                    saddFutures[i++] = cmd.sadd(index(emailIdReportName, emailId), report.getUniqueId());\n                    saddFutures[i++] = cmd.expire(index(emailIdReportName, emailId), expirationTime);\n                }\n            }\n            arrFutures.addAll(Lists.newArrayList(saddFutures));\n            cmd.flushCommands();\n            bin.flushCommands();\n            awaitRaw(arrFutures);\n            log.info(\"Successfully inserted reports\");\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForJob(String jobId, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] with frequency [{}]\", jobId, frequency);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobReportIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> freqReportIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobReportIds, freqReportIds);\n            Set<String> reportIds = jobReportIds.get();\n            reportIds.retainAll(freqReportIds.get());\n            return getAnomalyReports(reportIds, this);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForEmailId(String emailId) throws IOException {\n        log.info(\"Getting anomaly reports for Email ID [{}]\", emailId);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> emailReportIds = cmd.smembers(index(emailIdReportName, emailId));\n            cmd.flushCommands();\n            await(emailReportIds);\n            Set<String> reportIds = emailReportIds.get();\n            String[] rarr = new String[reportIds.size()];\n            int i = 0;\n            for (String s : reportIds) {\n                rarr[i] = s;\n                i++;\n            }\n            if (i > 0) {\n                RedisFuture<Long> removedReports = cmd.srem(index(emailIdReportName, emailId), rarr);\n                cmd.flushCommands();\n                await(removedReports);\n            }\n            log.info(\"Removed {} anomaly reports to send it to {}\", rarr.length, emailId);\n            return getAnomalyReports(reportIds, this);\n        } catch (Exception e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForJobAtTime(String jobId, String time, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] frequency [{}] at time [{}]\", jobId, frequency, time);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobRepIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> jobTimeIds = cmd.smembers(index(timeName, time));\n            RedisFuture<Set<String>> jobFreqIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobRepIds, jobTimeIds, jobFreqIds);\n            Set<String> reportIds = jobRepIds.get();\n            reportIds.retainAll(jobTimeIds.get());\n            reportIds.retainAll(jobFreqIds.get());\n            return getAnomalyReports(reportIds, this);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public void deleteAnomalyReportsForJob(String jobId) throws IOException {\n        log.info(\"Deleting all anomaly reports for job [{}]\", jobId);\n        try (RedisConnection<String> conn = connect();RedisConnection<byte[]> binary = binary()) {\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            Set<String> reportIds = cmd.smembers(index(jobIdName, jobId)).get();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            List<AnomalyReport> reports = getAnomalyReports(reportIds, this);\n            RedisFuture[] futures = new RedisFuture[(5 * reports.size()) + 1];\n            int i = 0;\n            for (AnomalyReport report : reports) {\n                futures[i++] = cmd.srem(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                futures[i++] = cmd.del(key(report.getUniqueId()));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\")));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\")));\n            }\n            futures[i] = cmd.del(index(jobIdName, jobId));\n            cmd.flushCommands();\n            bin.flushCommands();\n            await(futures);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error while deleting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public void deleteAnomalyReportsForJobAtTime(String jobId, String time, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] frequency [{}] at time [{}] for deletion\", jobId, frequency, time);\n        try (RedisConnection<String> conn = connect();RedisConnection<byte[]> binary = binary()) {\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobRepIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> jobTimeIds = cmd.smembers(index(timeName, time));\n            RedisFuture<Set<String>> jobFreqIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobRepIds, jobTimeIds, jobFreqIds);\n            Set<String> reportIds = jobRepIds.get();\n            reportIds.retainAll(jobTimeIds.get());\n            reportIds.retainAll(jobFreqIds.get());\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            List<AnomalyReport> reports = getAnomalyReports(reportIds, this);\n            RedisFuture[] futures = new RedisFuture[6 * reports.size()];\n            int i = 0;\n            for (AnomalyReport report : reports) {\n                futures[i++] = cmd.srem(index(jobIdName, report.getJobId()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                futures[i++] = cmd.del(key(report.getUniqueId()));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\")));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\")));\n            }\n            cmd.flushCommands();\n            bin.flushCommands();\n            await(futures);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while deleting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    protected static List<RedisFuture> writeReport(AsyncCommands<byte[]> bin, AsyncCommands<String> cmd, AnomalyReport report, long expirationTime, AbstractLettuceAccessor acc) {\n        List<int[]> timestamps = report.getAnomalyTimestampsHours();\n        Map<String, String> reportMap = acc.map(report);\n        reportMap.remove(DatabaseConstants.ANOMALY_TIMESTAMP);\n        byte[] keyStart = encode(acc.key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\"));\n        byte[] keyEnd = encode(acc.key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\"));\n        List<ScoredValue<byte[]>> valuesStart = new ArrayList<>(timestamps.size());\n        List<ScoredValue<byte[]>> valuesEnd = new ArrayList<>(timestamps.size());\n        for (int i = 0; i < timestamps.size(); i++) {\n            int[] timestamp = timestamps.get(i);\n            valuesStart.add(ScoredValue.fromNullable(((double) (i)), NumberUtils.toBytesCompressed(timestamp[0])));\n            if ((timestamp[1] != 0) && (timestamp[1] != timestamp[0])) {\n                valuesEnd.add(ScoredValue.fromNullable(((double) (i)), NumberUtils.toBytesCompressed(timestamp[1])));\n            }\n        }\n        List<RedisFuture> futures = new ArrayList<>(3);\n        futures.add(cmd.hmset(acc.key(report.getUniqueId()), reportMap));\n        futures.add(cmd.expire(acc.key(report.getUniqueId()), expirationTime));\n        log.info((((\"Report \" + report.getUniqueId()) + \" will expire in \") + (expirationTime / Constants.SECONDS_IN_DAY)) + \" days\");\n        if (!valuesStart.isEmpty()) {\n            futures.add(bin.zadd(keyStart, valuesStart.toArray(new ScoredValue[valuesStart.size()])));\n            futures.add(bin.expire(keyStart, expirationTime));\n        }\n        if (!valuesEnd.isEmpty()) {\n            futures.add(bin.zadd(keyEnd, valuesEnd.toArray(new ScoredValue[valuesEnd.size()])));\n            futures.add(bin.expire(keyEnd, expirationTime));\n        }\n        return futures;\n    }\n\n    protected static List<AnomalyReport> getAnomalyReports(Set<String> reportIds, AbstractLettuceAccessor acc) throws IOException {\n        try (RedisConnection<String> conn = acc.connect();RedisConnection<byte[]> binary = acc.binary()) {\n            List<RedisFuture<Map<String, String>>> values = new ArrayList<>(reportIds.size());\n            List<RedisFuture<List<ScoredValue<byte[]>>>> timeStart = new ArrayList<>(reportIds.size());\n            List<RedisFuture<List<ScoredValue<byte[]>>>> timeEnd = new ArrayList<>(reportIds.size());\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            for (String id : reportIds) {\n                byte[] keyStart = encode(acc.key(id, DatabaseConstants.ANOMALY_TIMESTAMP, \"start\"));\n                byte[] keyEnd = encode(acc.key(id, DatabaseConstants.ANOMALY_TIMESTAMP, \"end\"));\n                values.add(cmd.hgetall(acc.key(id)));\n                timeStart.add(bin.zrangeWithScores(keyStart, 0, -1));\n                timeEnd.add(bin.zrangeWithScores(keyEnd, 0, -1));\n            }\n            cmd.flushCommands();\n            bin.flushCommands();\n            List<RedisFuture[]> combine = Lists.newArrayList(values.toArray(new RedisFuture[values.size()]), timeStart.toArray(new RedisFuture[timeStart.size()]), timeEnd.toArray(new RedisFuture[timeEnd.size()]));\n            acc.awaitCollection(combine);\n            List<AnomalyReport> reports = new ArrayList<>(values.size());\n            for (int i = 0; i < values.size(); i++) {\n                AnomalyReport report = acc.unmap(AnomalyReport.class, values.get(i).get());\n                decodeAndSetTimestamp(report, timeStart.get(i).get(), timeEnd.get(i).get());\n                reports.add(report);\n            }\n            return reports;\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    protected static void decodeAndSetTimestamp(AnomalyReport report, List<ScoredValue<byte[]>> startVals, List<ScoredValue<byte[]>> endVals) {\n        byte[][] startBytes = new byte[startVals.size()][];\n        byte[][] endBytes = new byte[startVals.size()][];\n        for (ScoredValue<byte[]> val : startVals) {\n            startBytes[((int) (val.getScore()))] = val.getValue();\n        }\n        for (ScoredValue<byte[]> val : endVals) {\n            endBytes[((int) (val.getScore()))] = val.getValue();\n        }\n        report.setAnomalyTimestampsFromBytes(startBytes, endBytes);\n    }\n}\n\n'''\nthe error is triggered in the following specific lines in the previous code:\n            valuesStart.add(ScoredValue.fromNullable((double) i, NumberUtils.toBytesCompressed(timestamp[0])));\n                valuesEnd.add(ScoredValue.fromNullable((double) i, NumberUtils.toBytesCompressed(timestamp[1])));\nwith the following error message:\n[ERROR] /sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java:[289,24] incompatible types: no instance(s) of type variable(s) T,V exist so that io.lettuce.core.Value<V> conforms to io.lettuce.core.ScoredValue<byte[]>\n[ERROR] /sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java:[291,26] incompatible types: no instance(s) of type variable(s) T,V exist so that io.lettuce.core.Value<V> conforms to io.lettuce.core.ScoredValue<byte[]>\nThe error is caused by a change in the API of the dependency. The new library version includes the following changes:\nFormat: element | nature | kind\njava.lang.Object.toString | DELETION | METHOD_REMOVED\nio.lettuce.core.RedisURI.TIME_UNIT_MAP | DELETION | FIELD_REMOVED\nio.lettuce.core.cluster.RedisAdvancedClusterAsyncCommandsImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\njava.lang.Object.hashCode | DELETION | METHOD_REMOVED\njava.lang.Object.clone | DELETION | METHOD_REMOVED\nio.lettuce.core.RedisReactiveCommandsImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.AbstractRedisReactiveCommands.<init> | DELETION | CONSTRUCTOR_REMOVED\njava.lang.Object.hashCode | MUTATION | METHOD_NOW_FINAL\njava.lang.Object.notify | DELETION | METHOD_REMOVED\nio.lettuce.core.ConnectionBuilder.build | DELETION | METHOD_REMOVED\nio.lettuce.core.protocol.ConnectionWatchdog.<init> | DELETION | CONSTRUCTOR_REMOVED\njava.lang.Object.finalize | DELETION | METHOD_REMOVED\nio.lettuce.core.StatefulRedisConnectionImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.RedisAsyncCommandsImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\njava.lang.Object.notifyAll | DELETION | METHOD_REMOVED\nio.lettuce.core.codec.CompressionCodec.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.RedisURI$Builder.withTimeout | DELETION | METHOD_REMOVED\nio.lettuce.core.ScoredValue.from | MUTATION | METHOD_RETURN_TYPE_CHANGED\nio.lettuce.core.sentinel.RedisSentinelReactiveCommandsImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.AbstractRedisAsyncCommands.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.cluster.RedisAdvancedClusterReactiveCommandsImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\njava.lang.Object.equals | DELETION | METHOD_REMOVED\nio.lettuce.core.RedisURI.DEFAULT_TIMEOUT_UNIT | DELETION | FIELD_REMOVED\njava.lang.Object.getClass | DELETION | METHOD_REMOVED\nio.lettuce.core.RedisURI.getResolvedAddress | DELETION | METHOD_REMOVED\njava.lang.Object.wait | DELETION | METHOD_REMOVED\nio.lettuce.core.RedisURI.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.cluster.StatefulRedisClusterConnectionImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.SslConnectionBuilder.build | DELETION | METHOD_REMOVED\nio.lettuce.core.ScoredValue.fromNullable | MUTATION | METHOD_RETURN_TYPE_CHANGED\n\n- Identify the specific API changes that are causing the failure in the client code. \n- Compare the old and new API versions, noting any changes in method signatures, return types, or parameter lists. \n- Determine which parts of the client code need to be updated to accommodate these API changes. \n- Consider any constraints or requirements for the fix (e.g., not changing function signatures, potential import adjustments). \n- Plan the minimal set of changes needed to fix the issue while keeping the code functional and compliant with the new API. \n- Consider potential side effects of the proposed changes on other parts of the code. \n- Ensure that the planned changes will result in a complete and compilable class. \n- If applicable, note any additional imports that may be needed due to the API changes.  \n- Propose a patch that can be applied to the code to fix the issue. \n- Return only a complete and compilable class in a fenced code block. \n- You CANNOT change the function signature of any method but may create variables if it simplifies the code. \n- You CAN remove the @Override annotation IF AND ONLY IF the method no longer overrides a method in the updated dependency version. \n- If fixing the issue requires addressing missing imports, ensure the correct package or class is used in accordance with the newer dependency version. \n- Avoid removing any existing code unless it directly causes a compilation or functionality error. \n- Return only the fixed class, ensuring it fully compiles and adheres to these constraints.",
    "buggy_lines": "            valuesStart.add(ScoredValue.fromNullable((double) i, NumberUtils.toBytesCompressed(timestamp[0])));\n                valuesEnd.add(ScoredValue.fromNullable((double) i, NumberUtils.toBytesCompressed(timestamp[1])));",
    "error_message": "[ERROR] /sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java:[289,24] incompatible types: no instance(s) of type variable(s) T,V exist so that io.lettuce.core.Value<V> conforms to io.lettuce.core.ScoredValue<byte[]>\n[ERROR] /sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java:[291,26] incompatible types: no instance(s) of type variable(s) T,V exist so that io.lettuce.core.Value<V> conforms to io.lettuce.core.ScoredValue<byte[]>",
    "api_diff": "Format: element | nature | kind\njava.lang.Object.toString | DELETION | METHOD_REMOVED\nio.lettuce.core.RedisURI.TIME_UNIT_MAP | DELETION | FIELD_REMOVED\nio.lettuce.core.cluster.RedisAdvancedClusterAsyncCommandsImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\njava.lang.Object.hashCode | DELETION | METHOD_REMOVED\njava.lang.Object.clone | DELETION | METHOD_REMOVED\nio.lettuce.core.RedisReactiveCommandsImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.AbstractRedisReactiveCommands.<init> | DELETION | CONSTRUCTOR_REMOVED\njava.lang.Object.hashCode | MUTATION | METHOD_NOW_FINAL\njava.lang.Object.notify | DELETION | METHOD_REMOVED\nio.lettuce.core.ConnectionBuilder.build | DELETION | METHOD_REMOVED\nio.lettuce.core.protocol.ConnectionWatchdog.<init> | DELETION | CONSTRUCTOR_REMOVED\njava.lang.Object.finalize | DELETION | METHOD_REMOVED\nio.lettuce.core.StatefulRedisConnectionImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.RedisAsyncCommandsImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\njava.lang.Object.notifyAll | DELETION | METHOD_REMOVED\nio.lettuce.core.codec.CompressionCodec.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.RedisURI$Builder.withTimeout | DELETION | METHOD_REMOVED\nio.lettuce.core.ScoredValue.from | MUTATION | METHOD_RETURN_TYPE_CHANGED\nio.lettuce.core.sentinel.RedisSentinelReactiveCommandsImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.AbstractRedisAsyncCommands.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.cluster.RedisAdvancedClusterReactiveCommandsImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\njava.lang.Object.equals | DELETION | METHOD_REMOVED\nio.lettuce.core.RedisURI.DEFAULT_TIMEOUT_UNIT | DELETION | FIELD_REMOVED\njava.lang.Object.getClass | DELETION | METHOD_REMOVED\nio.lettuce.core.RedisURI.getResolvedAddress | DELETION | METHOD_REMOVED\njava.lang.Object.wait | DELETION | METHOD_REMOVED\nio.lettuce.core.RedisURI.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.cluster.StatefulRedisClusterConnectionImpl.<init> | DELETION | CONSTRUCTOR_REMOVED\nio.lettuce.core.SslConnectionBuilder.build | DELETION | METHOD_REMOVED\nio.lettuce.core.ScoredValue.fromNullable | MUTATION | METHOD_RETURN_TYPE_CHANGED",
    "original_code": "package com.yahoo.sherlock.store.redis;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ExecutionException;\nimport com.beust.jcommander.internal.Lists;\nimport com.yahoo.sherlock.model.AnomalyReport;\nimport com.yahoo.sherlock.settings.Constants;\nimport com.yahoo.sherlock.settings.DatabaseConstants;\nimport com.yahoo.sherlock.store.AnomalyReportAccessor;\nimport com.yahoo.sherlock.store.StoreParams;\nimport com.yahoo.sherlock.store.core.AsyncCommands;\nimport com.yahoo.sherlock.store.core.RedisConnection;\nimport com.yahoo.sherlock.utils.NumberUtils;\nimport io.lettuce.core.RedisFuture;\nimport io.lettuce.core.ScoredValue;\nimport lombok.extern.slf4j.Slf4j;\nimport static com.yahoo.sherlock.store.redis.Mapper.encode;\n@Slf4j\npublic class LettuceAnomalyReportAccessor extends AbstractLettuceAccessor implements AnomalyReportAccessor {\n    private final String jobIdName;\n\n    private final String timeName;\n\n    private final String frequencyName;\n\n    private final String emailIdReportName;\n\n    public LettuceAnomalyReportAccessor(StoreParams params) {\n        super(params);\n        this.jobIdName = params.get(DatabaseConstants.INDEX_REPORT_JOB_ID);\n        this.timeName = params.get(DatabaseConstants.INDEX_TIMESTAMP);\n        this.frequencyName = params.get(DatabaseConstants.INDEX_FREQUENCY);\n        this.emailIdReportName = params.get(DatabaseConstants.INDEX_EMAILID_REPORT);\n    }\n\n    protected static boolean isMissingId(AnomalyReport report) {\n        return (report.getUniqueId() == null) || report.getUniqueId().isEmpty();\n    }\n\n    @Override\n    public void putAnomalyReports(List<AnomalyReport> reports, List<String> emailIds) throws IOException {\n        log.info(\"Putting [{}] anomaly reports\", reports.size());\n        try (RedisConnection<String> conn = connect();RedisConnection<byte[]> binary = binary()) {\n            List<AnomalyReport> requireId = new ArrayList<>(reports.size());\n            List<AnomalyReport> ready = new ArrayList<>(reports.size());\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            for (AnomalyReport report : reports) {\n                if (isMissingId(report)) {\n                    requireId.add(report);\n                } else {\n                    ready.add(report);\n                }\n            }\n            if (!requireId.isEmpty()) {\n                log.info(\"Generating new IDs for [{}] reports\", requireId.size());\n                Integer[] newIds = newIds(requireId.size());\n                for (int i = 0; i < newIds.length; i++) {\n                    requireId.get(i).setUniqueId(newIds[i].toString());\n                }\n                ready.addAll(requireId);\n                requireId.clear();\n            }\n            List<RedisFuture> arrFutures = new ArrayList<>(ready.size() + 1);\n            RedisFuture[] saddFutures = new RedisFuture[ready.size() * (6 + (2 * emailIds.size()))];\n            int i = 0;\n            long expirationTime = Constants.SECONDS_IN_DAY * (ready.get(0).getJobFrequency().equalsIgnoreCase(Constants.HOUR) ? Constants.REDIS_RETENTION_WEEKS_IN_DAYS : ready.get(0).getJobFrequency().equalsIgnoreCase(Constants.MINUTE) ? Constants.REDIS_RETENTION_ONE_DAY : Constants.REDIS_RETENTION_YEARS_IN_DAYS);\n            for (AnomalyReport report : ready) {\n                arrFutures.addAll(writeReport(bin, cmd, report, expirationTime, this));\n                saddFutures[i++] = cmd.sadd(index(jobIdName, report.getJobId()), report.getUniqueId());\n                saddFutures[i++] = cmd.expire(index(jobIdName, report.getJobId()), expirationTime);\n                saddFutures[i++] = cmd.sadd(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                saddFutures[i++] = cmd.expire(index(frequencyName, report.getJobFrequency()), expirationTime);\n                saddFutures[i++] = cmd.sadd(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                saddFutures[i++] = cmd.expire(index(timeName, report.getReportQueryEndTime()), expirationTime);\n                for (String emailId : emailIds) {\n                    saddFutures[i++] = cmd.sadd(index(emailIdReportName, emailId), report.getUniqueId());\n                    saddFutures[i++] = cmd.expire(index(emailIdReportName, emailId), expirationTime);\n                }\n            }\n            arrFutures.addAll(Lists.newArrayList(saddFutures));\n            cmd.flushCommands();\n            bin.flushCommands();\n            awaitRaw(arrFutures);\n            log.info(\"Successfully inserted reports\");\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForJob(String jobId, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] with frequency [{}]\", jobId, frequency);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobReportIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> freqReportIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobReportIds, freqReportIds);\n            Set<String> reportIds = jobReportIds.get();\n            reportIds.retainAll(freqReportIds.get());\n            return getAnomalyReports(reportIds, this);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForEmailId(String emailId) throws IOException {\n        log.info(\"Getting anomaly reports for Email ID [{}]\", emailId);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> emailReportIds = cmd.smembers(index(emailIdReportName, emailId));\n            cmd.flushCommands();\n            await(emailReportIds);\n            Set<String> reportIds = emailReportIds.get();\n            String[] rarr = new String[reportIds.size()];\n            int i = 0;\n            for (String s : reportIds) {\n                rarr[i] = s;\n                i++;\n            }\n            if (i > 0) {\n                RedisFuture<Long> removedReports = cmd.srem(index(emailIdReportName, emailId), rarr);\n                cmd.flushCommands();\n                await(removedReports);\n            }\n            log.info(\"Removed {} anomaly reports to send it to {}\", rarr.length, emailId);\n            return getAnomalyReports(reportIds, this);\n        } catch (Exception e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForJobAtTime(String jobId, String time, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] frequency [{}] at time [{}]\", jobId, frequency, time);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobRepIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> jobTimeIds = cmd.smembers(index(timeName, time));\n            RedisFuture<Set<String>> jobFreqIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobRepIds, jobTimeIds, jobFreqIds);\n            Set<String> reportIds = jobRepIds.get();\n            reportIds.retainAll(jobTimeIds.get());\n            reportIds.retainAll(jobFreqIds.get());\n            return getAnomalyReports(reportIds, this);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public void deleteAnomalyReportsForJob(String jobId) throws IOException {\n        log.info(\"Deleting all anomaly reports for job [{}]\", jobId);\n        try (RedisConnection<String> conn = connect();RedisConnection<byte[]> binary = binary()) {\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            Set<String> reportIds = cmd.smembers(index(jobIdName, jobId)).get();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            List<AnomalyReport> reports = getAnomalyReports(reportIds, this);\n            RedisFuture[] futures = new RedisFuture[(5 * reports.size()) + 1];\n            int i = 0;\n            for (AnomalyReport report : reports) {\n                futures[i++] = cmd.srem(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                futures[i++] = cmd.del(key(report.getUniqueId()));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\")));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\")));\n            }\n            futures[i] = cmd.del(index(jobIdName, jobId));\n            cmd.flushCommands();\n            bin.flushCommands();\n            await(futures);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error while deleting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public void deleteAnomalyReportsForJobAtTime(String jobId, String time, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] frequency [{}] at time [{}] for deletion\", jobId, frequency, time);\n        try (RedisConnection<String> conn = connect();RedisConnection<byte[]> binary = binary()) {\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobRepIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> jobTimeIds = cmd.smembers(index(timeName, time));\n            RedisFuture<Set<String>> jobFreqIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobRepIds, jobTimeIds, jobFreqIds);\n            Set<String> reportIds = jobRepIds.get();\n            reportIds.retainAll(jobTimeIds.get());\n            reportIds.retainAll(jobFreqIds.get());\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            List<AnomalyReport> reports = getAnomalyReports(reportIds, this);\n            RedisFuture[] futures = new RedisFuture[6 * reports.size()];\n            int i = 0;\n            for (AnomalyReport report : reports) {\n                futures[i++] = cmd.srem(index(jobIdName, report.getJobId()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                futures[i++] = cmd.del(key(report.getUniqueId()));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\")));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\")));\n            }\n            cmd.flushCommands();\n            bin.flushCommands();\n            await(futures);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while deleting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    protected static List<RedisFuture> writeReport(AsyncCommands<byte[]> bin, AsyncCommands<String> cmd, AnomalyReport report, long expirationTime, AbstractLettuceAccessor acc) {\n        List<int[]> timestamps = report.getAnomalyTimestampsHours();\n        Map<String, String> reportMap = acc.map(report);\n        reportMap.remove(DatabaseConstants.ANOMALY_TIMESTAMP);\n        byte[] keyStart = encode(acc.key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\"));\n        byte[] keyEnd = encode(acc.key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\"));\n        List<ScoredValue<byte[]>> valuesStart = new ArrayList<>(timestamps.size());\n        List<ScoredValue<byte[]>> valuesEnd = new ArrayList<>(timestamps.size());\n        for (int i = 0; i < timestamps.size(); i++) {\n            int[] timestamp = timestamps.get(i);\n            valuesStart.add(ScoredValue.fromNullable(((double) (i)), NumberUtils.toBytesCompressed(timestamp[0])));\n            if ((timestamp[1] != 0) && (timestamp[1] != timestamp[0])) {\n                valuesEnd.add(ScoredValue.fromNullable(((double) (i)), NumberUtils.toBytesCompressed(timestamp[1])));\n            }\n        }\n        List<RedisFuture> futures = new ArrayList<>(3);\n        futures.add(cmd.hmset(acc.key(report.getUniqueId()), reportMap));\n        futures.add(cmd.expire(acc.key(report.getUniqueId()), expirationTime));\n        log.info((((\"Report \" + report.getUniqueId()) + \" will expire in \") + (expirationTime / Constants.SECONDS_IN_DAY)) + \" days\");\n        if (!valuesStart.isEmpty()) {\n            futures.add(bin.zadd(keyStart, valuesStart.toArray(new ScoredValue[valuesStart.size()])));\n            futures.add(bin.expire(keyStart, expirationTime));\n        }\n        if (!valuesEnd.isEmpty()) {\n            futures.add(bin.zadd(keyEnd, valuesEnd.toArray(new ScoredValue[valuesEnd.size()])));\n            futures.add(bin.expire(keyEnd, expirationTime));\n        }\n        return futures;\n    }\n\n    protected static List<AnomalyReport> getAnomalyReports(Set<String> reportIds, AbstractLettuceAccessor acc) throws IOException {\n        try (RedisConnection<String> conn = acc.connect();RedisConnection<byte[]> binary = acc.binary()) {\n            List<RedisFuture<Map<String, String>>> values = new ArrayList<>(reportIds.size());\n            List<RedisFuture<List<ScoredValue<byte[]>>>> timeStart = new ArrayList<>(reportIds.size());\n            List<RedisFuture<List<ScoredValue<byte[]>>>> timeEnd = new ArrayList<>(reportIds.size());\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            for (String id : reportIds) {\n                byte[] keyStart = encode(acc.key(id, DatabaseConstants.ANOMALY_TIMESTAMP, \"start\"));\n                byte[] keyEnd = encode(acc.key(id, DatabaseConstants.ANOMALY_TIMESTAMP, \"end\"));\n                values.add(cmd.hgetall(acc.key(id)));\n                timeStart.add(bin.zrangeWithScores(keyStart, 0, -1));\n                timeEnd.add(bin.zrangeWithScores(keyEnd, 0, -1));\n            }\n            cmd.flushCommands();\n            bin.flushCommands();\n            List<RedisFuture[]> combine = Lists.newArrayList(values.toArray(new RedisFuture[values.size()]), timeStart.toArray(new RedisFuture[timeStart.size()]), timeEnd.toArray(new RedisFuture[timeEnd.size()]));\n            acc.awaitCollection(combine);\n            List<AnomalyReport> reports = new ArrayList<>(values.size());\n            for (int i = 0; i < values.size(); i++) {\n                AnomalyReport report = acc.unmap(AnomalyReport.class, values.get(i).get());\n                decodeAndSetTimestamp(report, timeStart.get(i).get(), timeEnd.get(i).get());\n                reports.add(report);\n            }\n            return reports;\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    protected static void decodeAndSetTimestamp(AnomalyReport report, List<ScoredValue<byte[]>> startVals, List<ScoredValue<byte[]>> endVals) {\n        byte[][] startBytes = new byte[startVals.size()][];\n        byte[][] endBytes = new byte[startVals.size()][];\n        for (ScoredValue<byte[]> val : startVals) {\n            startBytes[((int) (val.getScore()))] = val.getValue();\n        }\n        for (ScoredValue<byte[]> val : endVals) {\n            endBytes[((int) (val.getScore()))] = val.getValue();\n        }\n        report.setAnomalyTimestampsFromBytes(startBytes, endBytes);\n    }\n}\n",
    "project": "sherlock",
    "libraryName": "lettuce-core",
    "libraryGroupID": "io.lettuce",
    "newVersion": "6.5.1.RELEASE",
    "previousVersion": "5.1.6.RELEASE",
    "breakingCommit": "7e1c7826b63cae9a472d707f4fb65b6add69b48e",
    "patch": "```java\npackage com.yahoo.sherlock.store.redis;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ExecutionException;\nimport com.beust.jcommander.internal.Lists;\nimport com.yahoo.sherlock.model.AnomalyReport;\nimport com.yahoo.sherlock.settings.Constants;\nimport com.yahoo.sherlock.settings.DatabaseConstants;\nimport com.yahoo.sherlock.store.AnomalyReportAccessor;\nimport com.yahoo.sherlock.store.StoreParams;\nimport com.yahoo.sherlock.store.core.AsyncCommands;\nimport com.yahoo.sherlock.store.core.RedisConnection;\nimport com.yahoo.sherlock.utils.NumberUtils;\nimport io.lettuce.core.RedisFuture;\nimport io.lettuce.core.ScoredValue;\nimport lombok.extern.slf4j.Slf4j;\nimport static com.yahoo.sherlock.store.redis.Mapper.encode;\n@Slf4j\npublic class LettuceAnomalyReportAccessor extends AbstractLettuceAccessor implements AnomalyReportAccessor {\n    private final String jobIdName;\n    private final String timeName;\n    private final String frequencyName;\n    private final String emailIdReportName;\n\n    public LettuceAnomalyReportAccessor(StoreParams params) {\n        super(params);\n        this.jobIdName = params.get(DatabaseConstants.INDEX_REPORT_JOB_ID);\n        this.timeName = params.get(DatabaseConstants.INDEX_TIMESTAMP);\n        this.frequencyName = params.get(DatabaseConstants.INDEX_FREQUENCY);\n        this.emailIdReportName = params.get(DatabaseConstants.INDEX_EMAILID_REPORT);\n    }\n\n    protected static boolean isMissingId(AnomalyReport report) {\n        return (report.getUniqueId() == null) || report.getUniqueId().isEmpty();\n    }\n\n    @Override\n    public void putAnomalyReports(List<AnomalyReport> reports, List<String> emailIds) throws IOException {\n        log.info(\"Putting [{}] anomaly reports\", reports.size());\n        try (RedisConnection<String> conn = connect(); RedisConnection<byte[]> binary = binary()) {\n            List<AnomalyReport> requireId = new ArrayList<>(reports.size());\n            List<AnomalyReport> ready = new ArrayList<>(reports.size());\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            for (AnomalyReport report : reports) {\n                if (isMissingId(report)) {\n                    requireId.add(report);\n                } else {\n                    ready.add(report);\n                }\n            }\n            if (!requireId.isEmpty()) {\n                log.info(\"Generating new IDs for [{}] reports\", requireId.size());\n                Integer[] newIds = newIds(requireId.size());\n                for (int i = 0; i < newIds.length; i++) {\n                    requireId.get(i).setUniqueId(newIds[i].toString());\n                }\n                ready.addAll(requireId);\n                requireId.clear();\n            }\n            List<RedisFuture> arrFutures = new ArrayList<>(ready.size() + 1);\n            RedisFuture[] saddFutures = new RedisFuture[ready.size() * (6 + (2 * emailIds.size()))];\n            long expirationTime = Constants.SECONDS_IN_DAY * (ready.get(0).getJobFrequency().equalsIgnoreCase(Constants.HOUR) ? Constants.REDIS_RETENTION_WEEKS_IN_DAYS : ready.get(0).getJobFrequency().equalsIgnoreCase(Constants.MINUTE) ? Constants.REDIS_RETENTION_ONE_DAY : Constants.REDIS_RETENTION_YEARS_IN_DAYS);\n            for (AnomalyReport report : ready) {\n                arrFutures.addAll(writeReport(bin, cmd, report, expirationTime, this));\n                saddFutures[0] = cmd.sadd(index(jobIdName, report.getJobId()), report.getUniqueId());\n                saddFutures[1] = cmd.expire(index(jobIdName, report.getJobId()), expirationTime);\n                saddFutures[2] = cmd.sadd(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                saddFutures[3] = cmd.expire(index(frequencyName, report.getJobFrequency()), expirationTime);\n                saddFutures[4] = cmd.sadd(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                saddFutures[5] = cmd.expire(index(timeName, report.getReportQueryEndTime()), expirationTime);\n                for (String emailId : emailIds) {\n                    saddFutures[6] = cmd.sadd(index(emailIdReportName, emailId), report.getUniqueId());\n                    saddFutures[7] = cmd.expire(index(emailIdReportName, emailId), expirationTime);\n                }\n            }\n            arrFutures.addAll(Lists.newArrayList(saddFutures));\n            cmd.flushCommands();\n            bin.flushCommands();\n            awaitRaw(arrFutures);\n            log.info(\"Successfully inserted reports\");\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForJob(String jobId, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] with frequency [{}]\", jobId, frequency);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobReportIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> freqReportIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobReportIds, freqReportIds);\n            Set<String> reportIds = jobReportIds.get();\n            reportIds.retainAll(freqReportIds.get());\n            return getAnomalyReports(reportIds, this);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForEmailId(String emailId) throws IOException {\n        log.info(\"Getting anomaly reports for Email ID [{}]\", emailId);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> emailReportIds = cmd.smembers(index(emailIdReportName, emailId));\n            cmd.flushCommands();\n            await(emailReportIds);\n            Set<String> reportIds = emailReportIds.get();\n            String[] rarr = new String[reportIds.size()];\n            int i = 0;\n            for (String s : reportIds) {\n                rarr[i] = s;\n                i++;\n            }\n            if (i > 0) {\n                RedisFuture removedReports = cmd.srem(index(emailIdReportName, emailId), rarr);\n                cmd.flushCommands();\n                await(removedReports);\n            }\n            log.info(\"Removed {} anomaly reports to send it to {}\", rarr.length, emailId);\n            return getAnomalyReports(reportIds, this);\n        } catch (Exception e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForJobAtTime(String jobId, String time, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] frequency [{}] at time [{}]\", jobId, frequency, time);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobRepIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> jobTimeIds = cmd.smembers(index(timeName, time));\n            RedisFuture<Set<String>> jobFreqIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobRepIds, jobTimeIds, jobFreqIds);\n            Set<String> reportIds = jobRepIds.get();\n            reportIds.retainAll(jobTimeIds.get());\n            reportIds.retainAll(jobFreqIds.get());\n            return getAnomalyReports(reportIds, this);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public void deleteAnomalyReportsForJob(String jobId) throws IOException {\n        log.info(\"Deleting all anomaly reports for job [{}]\", jobId);\n        try (RedisConnection<String> conn = connect(); RedisConnection<byte[]> binary = binary()) {\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            Set<String> reportIds = cmd.smembers(index(jobIdName, jobId)).get();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            List<AnomalyReport> reports = getAnomalyReports(reportIds, this);\n            RedisFuture[] futures = new RedisFuture[(5 * reports.size()) + 1];\n            int i = 0;\n            for (AnomalyReport report : reports) {\n                futures[i++] = cmd.srem(index(jobIdName, report.getJobId()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                futures[i++] = cmd.del(key(report.getUniqueId()));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\")));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\")));\n            }\n            futures[i] = cmd.del(index(jobIdName, jobId));\n            cmd.flushCommands();\n            bin.flushCommands();\n            await(futures);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error while deleting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public void deleteAnomalyReportsForJobAtTime(String jobId, String time, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] frequency [{}] at time [{}] for deletion\", jobId, frequency, time);\n        try (RedisConnection<String> conn = connect(); RedisConnection<byte[]> binary = binary()) {\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobRepIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> jobTimeIds = cmd.smembers(index(timeName, time));\n            RedisFuture<Set<String>> jobFreqIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobRepIds, jobTimeIds, jobFreqIds);\n            Set<String> reportIds = jobRepIds.get();\n            reportIds.retainAll(jobTimeIds.get());\n            reportIds.retainAll(jobFreqIds.get());\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            List<AnomalyReport> reports = getAnomalyReports(reportIds, this);\n            RedisFuture[] futures = new RedisFuture[6 * reports.size()];\n            int i = 0;\n            for (AnomalyReport report : reports) {\n                futures[i++] = cmd.srem(index(jobIdName, report.getJobId()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                futures[i++] = cmd.del(key(report.getUniqueId()));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\")));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\")));\n            }\n            cmd.flushCommands();\n            bin.flushCommands();\n            await(futures);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while deleting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForJob(String jobId, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] with frequency [{}]\", jobId, frequency);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobReportIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> freqReportIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobReportIds, freqReportIds);\n            Set<String> reportIds = jobReportIds.get();\n            reportIds.retainAll(freqReportIds.get());\n            return getAnomalyReports(reportIds, this);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n}\n```<end_of_turn>"
}