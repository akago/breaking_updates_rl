{
    "absolute_path_to_file_in_container": "/sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java",
    "errors": [
        {
            "line_number": 289,
            "message": "[ERROR] /sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java:[289,24] incompatible types: no instance(s) of type variable(s) T,V exist so that io.lettuce.core.Value<V> conforms to io.lettuce.core.ScoredValue<byte[]>",
            "additional_info": "",
            "file_name": "LettuceAnomalyReportAccessor.java",
            "BCs": [],
            "Additions": [],
            "uid": "18809662-a82d-578a-a742-32a7717c8fc9"
        },
        {
            "line_number": 291,
            "message": "[ERROR] /sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java:[291,26] incompatible types: no instance(s) of type variable(s) T,V exist so that io.lettuce.core.Value<V> conforms to io.lettuce.core.ScoredValue<byte[]>",
            "additional_info": "",
            "file_name": "LettuceAnomalyReportAccessor.java",
            "BCs": [],
            "Additions": [],
            "uid": "18809662-a82d-578a-a742-32a7717c8fc9"
        }
    ],
    "prompt": "\nThe following Java client code fails: \n'''java\n/*\n * Copyright 2017, Yahoo Holdings Inc.\n * Copyrights licensed under the GPL License.\n * See the accompanying LICENSE file for terms.\n */\n\npackage com.yahoo.sherlock.store.redis;\n\nimport com.beust.jcommander.internal.Lists;\nimport io.lettuce.core.RedisFuture;\nimport io.lettuce.core.ScoredValue;\nimport com.yahoo.sherlock.model.AnomalyReport;\nimport com.yahoo.sherlock.settings.Constants;\nimport com.yahoo.sherlock.settings.DatabaseConstants;\nimport com.yahoo.sherlock.store.AnomalyReportAccessor;\nimport com.yahoo.sherlock.store.StoreParams;\nimport com.yahoo.sherlock.store.core.AsyncCommands;\nimport com.yahoo.sherlock.store.core.RedisConnection;\nimport com.yahoo.sherlock.utils.NumberUtils;\nimport lombok.extern.slf4j.Slf4j;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ExecutionException;\n\nimport static com.yahoo.sherlock.store.redis.Mapper.encode;\n\n/**\n * Anomaly report accessor implemented for clusters using Lettuce.\n */\n@Slf4j\npublic class LettuceAnomalyReportAccessor\n        extends AbstractLettuceAccessor\n        implements AnomalyReportAccessor {\n\n    private final String jobIdName;\n    private final String timeName;\n    private final String frequencyName;\n    private final String emailIdReportName;\n\n    /**\n     * @param params store params\n     */\n    public LettuceAnomalyReportAccessor(StoreParams params) {\n        super(params);\n        this.jobIdName = params.get(DatabaseConstants.INDEX_REPORT_JOB_ID);\n        this.timeName = params.get(DatabaseConstants.INDEX_TIMESTAMP);\n        this.frequencyName = params.get(DatabaseConstants.INDEX_FREQUENCY);\n        this.emailIdReportName = params.get(DatabaseConstants.INDEX_EMAILID_REPORT);\n    }\n\n    /**\n     * @param report report to check ID\n     * @return whether the report has an assigned ID\n     */\n    protected static boolean isMissingId(AnomalyReport report) {\n        return report.getUniqueId() == null || report.getUniqueId().isEmpty();\n    }\n\n    @Override\n    public void putAnomalyReports(List<AnomalyReport> reports, List<String> emailIds) throws IOException {\n        log.info(\"Putting [{}] anomaly reports\", reports.size());\n        try (\n                RedisConnection<String> conn = connect();\n                RedisConnection<byte[]> binary = binary()\n        ) {\n            List<AnomalyReport> requireId = new ArrayList<>(reports.size());\n            List<AnomalyReport> ready = new ArrayList<>(reports.size());\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            for (AnomalyReport report : reports) {\n                if (isMissingId(report)) {\n                    requireId.add(report);\n                } else {\n                    ready.add(report);\n                }\n            }\n            if (!requireId.isEmpty()) {\n                log.info(\"Generating new IDs for [{}] reports\", requireId.size());\n                Integer[] newIds = newIds(requireId.size());\n                for (int i = 0; i < newIds.length; i++) {\n                    requireId.get(i).setUniqueId(newIds[i].toString());\n                }\n                ready.addAll(requireId);\n                requireId.clear();\n            }\n            List<RedisFuture> arrFutures = new ArrayList<>(ready.size() + 1);\n            RedisFuture[] saddFutures = new RedisFuture[ready.size() * (6 + 2 * emailIds.size())];\n            int i = 0;\n            long expirationTime = Constants.SECONDS_IN_DAY * (ready.get(0).getJobFrequency().equalsIgnoreCase(Constants.HOUR) ?\n                                                              Constants.REDIS_RETENTION_WEEKS_IN_DAYS : (ready.get(0).getJobFrequency().equalsIgnoreCase(Constants.MINUTE) ?\n                                                                                                        Constants.REDIS_RETENTION_ONE_DAY : Constants.REDIS_RETENTION_YEARS_IN_DAYS));\n            for (AnomalyReport report : ready) {\n                arrFutures.addAll(writeReport(bin, cmd, report, expirationTime, this));\n                saddFutures[i++] = cmd.sadd(index(jobIdName, report.getJobId()), report.getUniqueId());\n                saddFutures[i++] = cmd.expire(index(jobIdName, report.getJobId()), expirationTime);\n                saddFutures[i++] = cmd.sadd(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                saddFutures[i++] = cmd.expire(index(frequencyName, report.getJobFrequency()), expirationTime);\n                saddFutures[i++] = cmd.sadd(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                saddFutures[i++] = cmd.expire(index(timeName, report.getReportQueryEndTime()), expirationTime);\n                for (String emailId : emailIds) {\n                    saddFutures[i++] = cmd.sadd(index(emailIdReportName, emailId), report.getUniqueId());\n                    saddFutures[i++] = cmd.expire(index(emailIdReportName, emailId), expirationTime);\n                }\n            }\n            arrFutures.addAll(Lists.newArrayList(saddFutures));\n            cmd.flushCommands();\n            bin.flushCommands();\n            awaitRaw(arrFutures);\n            log.info(\"Successfully inserted reports\");\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForJob(String jobId, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] with frequency [{}]\", jobId, frequency);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobReportIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> freqReportIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobReportIds, freqReportIds);\n            Set<String> reportIds = jobReportIds.get();\n            reportIds.retainAll(freqReportIds.get());\n            return getAnomalyReports(reportIds, this);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForEmailId(String emailId) throws IOException {\n        log.info(\"Getting anomaly reports for Email ID [{}]\", emailId);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> emailReportIds = cmd.smembers(index(emailIdReportName, emailId));\n            cmd.flushCommands();\n            await(emailReportIds);\n            Set<String> reportIds = emailReportIds.get();\n            String[] rarr = new String[reportIds.size()];\n            int i = 0;\n            for (String s : reportIds) {\n                rarr[i] = s; i++;\n            }\n            if (i > 0) {\n                RedisFuture<Long> removedReports = cmd.srem(index(emailIdReportName, emailId), rarr);\n                cmd.flushCommands();\n                await(removedReports);\n            }\n            log.info(\"Removed {} anomaly reports to send it to {}\", rarr.length, emailId);\n            return getAnomalyReports(reportIds, this);\n        } catch (Exception e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForJobAtTime(String jobId, String time, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] frequency [{}] at time [{}]\", jobId, frequency, time);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobRepIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> jobTimeIds = cmd.smembers(index(timeName, time));\n            RedisFuture<Set<String>> jobFreqIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobRepIds, jobTimeIds, jobFreqIds);\n            Set<String> reportIds = jobRepIds.get();\n            reportIds.retainAll(jobTimeIds.get());\n            reportIds.retainAll(jobFreqIds.get());\n            return getAnomalyReports(reportIds, this);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public void deleteAnomalyReportsForJob(String jobId) throws IOException {\n        log.info(\"Deleting all anomaly reports for job [{}]\", jobId);\n        try (\n                RedisConnection<String> conn = connect();\n                RedisConnection<byte[]> binary = binary()\n        ) {\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            Set<String> reportIds = cmd.smembers(index(jobIdName, jobId)).get();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            List<AnomalyReport> reports = getAnomalyReports(reportIds, this);\n            RedisFuture[] futures = new RedisFuture[5 * reports.size() + 1];\n            int i = 0;\n            for (AnomalyReport report : reports) {\n                futures[i++] = cmd.srem(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                futures[i++] = cmd.del(key(report.getUniqueId()));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\")));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\")));\n            }\n            futures[i] = cmd.del(index(jobIdName, jobId));\n            cmd.flushCommands();\n            bin.flushCommands();\n            await(futures);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error while deleting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public void deleteAnomalyReportsForJobAtTime(String jobId, String time, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] frequency [{}] at time [{}] for deletion\", jobId, frequency, time);\n        try (\n            RedisConnection<String> conn = connect();\n            RedisConnection<byte[]> binary = binary()\n        ) {\n            // Get all report IDs\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobRepIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> jobTimeIds = cmd.smembers(index(timeName, time));\n            RedisFuture<Set<String>> jobFreqIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobRepIds, jobTimeIds, jobFreqIds);\n            Set<String> reportIds = jobRepIds.get();\n            reportIds.retainAll(jobTimeIds.get());\n            reportIds.retainAll(jobFreqIds.get());\n            // Delete the reports\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            List<AnomalyReport> reports = getAnomalyReports(reportIds, this);\n            RedisFuture[] futures = new RedisFuture[6 * reports.size()];\n            int i = 0;\n            for (AnomalyReport report : reports) {\n                futures[i++] = cmd.srem(index(jobIdName, report.getJobId()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                futures[i++] = cmd.del(key(report.getUniqueId()));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\")));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\")));\n            }\n            cmd.flushCommands();\n            bin.flushCommands();\n            await(futures);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while deleting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Write a report to the store, exacting the timestamps and\n     * encoding them as bytes.\n     *\n     * @param bin    binary commands\n     * @param cmd    string commands\n     * @param report report to write\n     * @param expirationTime expiration time of the key\n     * @param acc    accessor instance\n     * @return an array of futures that need to be awaited\n     */\n    @SuppressWarnings(\"unchecked\")\n    protected static List<RedisFuture> writeReport(\n            AsyncCommands<byte[]> bin,\n            AsyncCommands<String> cmd,\n            AnomalyReport report,\n            long expirationTime,\n            AbstractLettuceAccessor acc\n    ) {\n        List<int[]> timestamps = report.getAnomalyTimestampsHours();\n        Map<String, String> reportMap = acc.map(report);\n        reportMap.remove(DatabaseConstants.ANOMALY_TIMESTAMP);\n        byte[] keyStart = encode(acc.key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\"));\n        byte[] keyEnd = encode(acc.key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\"));\n        List<ScoredValue<byte[]>> valuesStart = new ArrayList<>(timestamps.size());\n        List<ScoredValue<byte[]>> valuesEnd = new ArrayList<>(timestamps.size());\n        for (int i = 0; i < timestamps.size(); i++) {\n            int[] timestamp = timestamps.get(i);\n            valuesStart.add(ScoredValue.fromNullable((double) i, NumberUtils.toBytesCompressed(timestamp[0])));\n            if (timestamp[1] != 0 && timestamp[1] != timestamp[0]) {\n                valuesEnd.add(ScoredValue.fromNullable((double) i, NumberUtils.toBytesCompressed(timestamp[1])));\n            }\n        }\n        List<RedisFuture> futures = new ArrayList<>(3);\n        futures.add(cmd.hmset(acc.key(report.getUniqueId()), reportMap));\n        futures.add(cmd.expire(acc.key(report.getUniqueId()), expirationTime));\n        log.info(\"Report \" + report.getUniqueId() + \" will expire in \" + expirationTime / Constants.SECONDS_IN_DAY + \" days\");\n        if (!valuesStart.isEmpty()) {\n            futures.add(bin.zadd(keyStart, valuesStart.toArray(new ScoredValue[valuesStart.size()])));\n            futures.add(bin.expire(keyStart, expirationTime));\n        }\n        if (!valuesEnd.isEmpty()) {\n            futures.add(bin.zadd(keyEnd, valuesEnd.toArray(new ScoredValue[valuesEnd.size()])));\n            futures.add(bin.expire(keyEnd, expirationTime));\n        }\n        return futures;\n    }\n\n    /**\n     * Get a list of anomaly reports corresponding\n     * to a set of report IDs.\n     *\n     * @param reportIds set of report IDs\n     * @param acc       accessor instance\n     * @return list of anomaly reports\n     * @throws IOException if an error occurs\n     */\n    protected static List<AnomalyReport> getAnomalyReports(\n            Set<String> reportIds,\n            AbstractLettuceAccessor acc\n    ) throws IOException {\n        try (\n                RedisConnection<String> conn = acc.connect();\n                RedisConnection<byte[]> binary = acc.binary()\n        ) {\n            List<RedisFuture<Map<String, String>>> values = new ArrayList<>(reportIds.size());\n            List<RedisFuture<List<ScoredValue<byte[]>>>> timeStart = new ArrayList<>(reportIds.size());\n            List<RedisFuture<List<ScoredValue<byte[]>>>> timeEnd = new ArrayList<>(reportIds.size());\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            for (String id : reportIds) {\n                byte[] keyStart = encode(acc.key(id, DatabaseConstants.ANOMALY_TIMESTAMP, \"start\"));\n                byte[] keyEnd = encode(acc.key(id, DatabaseConstants.ANOMALY_TIMESTAMP, \"end\"));\n                values.add(cmd.hgetall(acc.key(id)));\n                timeStart.add(bin.zrangeWithScores(keyStart, 0, -1));\n                timeEnd.add(bin.zrangeWithScores(keyEnd, 0, -1));\n            }\n            cmd.flushCommands();\n            bin.flushCommands();\n            List<RedisFuture[]> combine = Lists.newArrayList(\n                    values.toArray(new RedisFuture[values.size()]),\n                    timeStart.toArray(new RedisFuture[timeStart.size()]),\n                    timeEnd.toArray(new RedisFuture[timeEnd.size()])\n            );\n            acc.awaitCollection(combine);\n            List<AnomalyReport> reports = new ArrayList<>(values.size());\n            for (int i = 0; i < values.size(); i++) {\n                AnomalyReport report = acc.unmap(AnomalyReport.class, values.get(i).get());\n                decodeAndSetTimestamp(report, timeStart.get(i).get(), timeEnd.get(i).get());\n                reports.add(report);\n            }\n            return reports;\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Decode timestamps from lettuce responses.\n     *\n     * @param report    report to set timestamps\n     * @param startVals starting scored values\n     * @param endVals   ending scored values\n     */\n    protected static void decodeAndSetTimestamp(\n            AnomalyReport report,\n            List<ScoredValue<byte[]>> startVals,\n            List<ScoredValue<byte[]>> endVals\n    ) {\n        byte[][] startBytes = new byte[startVals.size()][];\n        byte[][] endBytes = new byte[startVals.size()][];\n        for (ScoredValue<byte[]> val : startVals) {\n            startBytes[(int) val.getScore()] = val.getValue();\n        }\n        for (ScoredValue<byte[]> val : endVals) {\n            endBytes[(int) val.getScore()] = val.getValue();\n        }\n        report.setAnomalyTimestampsFromBytes(startBytes, endBytes);\n    }\n\n}\n\n'''\nThe error is caused by a change in the API of the dependency: lettuce-core 5.1.6.RELEASE->6.5.1.RELEASE. \nThe new library version includes the following relevant backward incompatible changes on API. \n(API changes format: lines starting with '--' denote removed members, '++' denote added ones, '~~' denote mutations with change kind) \n-- io.lettuce.core.RedisURI$Builder.withTimeout\n\nThe error is triggered in the following specific lines in the previous code:\n            valuesStart.add(ScoredValue.fromNullable((double) i, NumberUtils.toBytesCompressed(timestamp[0])));\n                valuesEnd.add(ScoredValue.fromNullable((double) i, NumberUtils.toBytesCompressed(timestamp[1])));\nwith the following error message:\n[ERROR] /sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java:[289,24] incompatible types: no instance(s) of type variable(s) T,V exist so that io.lettuce.core.Value<V> conforms to io.lettuce.core.ScoredValue<byte[]>\n[ERROR] /sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java:[291,26] incompatible types: no instance(s) of type variable(s) T,V exist so that io.lettuce.core.Value<V> conforms to io.lettuce.core.ScoredValue<byte[]>\n\nPlease apply your reasoning and generate the fix following the system instruction.\n",
    "buggy_lines": "            valuesStart.add(ScoredValue.fromNullable((double) i, NumberUtils.toBytesCompressed(timestamp[0])));\n                valuesEnd.add(ScoredValue.fromNullable((double) i, NumberUtils.toBytesCompressed(timestamp[1])));",
    "error_message": "[ERROR] /sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java:[289,24] incompatible types: no instance(s) of type variable(s) T,V exist so that io.lettuce.core.Value<V> conforms to io.lettuce.core.ScoredValue<byte[]>\n[ERROR] /sherlock/src/main/java/com/yahoo/sherlock/store/redis/LettuceAnomalyReportAccessor.java:[291,26] incompatible types: no instance(s) of type variable(s) T,V exist so that io.lettuce.core.Value<V> conforms to io.lettuce.core.ScoredValue<byte[]>",
    "api_diff": "-- io.lettuce.core.RedisURI$Builder.withTimeout",
    "original_code": "/*\n * Copyright 2017, Yahoo Holdings Inc.\n * Copyrights licensed under the GPL License.\n * See the accompanying LICENSE file for terms.\n */\n\npackage com.yahoo.sherlock.store.redis;\n\nimport com.beust.jcommander.internal.Lists;\nimport io.lettuce.core.RedisFuture;\nimport io.lettuce.core.ScoredValue;\nimport com.yahoo.sherlock.model.AnomalyReport;\nimport com.yahoo.sherlock.settings.Constants;\nimport com.yahoo.sherlock.settings.DatabaseConstants;\nimport com.yahoo.sherlock.store.AnomalyReportAccessor;\nimport com.yahoo.sherlock.store.StoreParams;\nimport com.yahoo.sherlock.store.core.AsyncCommands;\nimport com.yahoo.sherlock.store.core.RedisConnection;\nimport com.yahoo.sherlock.utils.NumberUtils;\nimport lombok.extern.slf4j.Slf4j;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ExecutionException;\n\nimport static com.yahoo.sherlock.store.redis.Mapper.encode;\n\n/**\n * Anomaly report accessor implemented for clusters using Lettuce.\n */\n@Slf4j\npublic class LettuceAnomalyReportAccessor\n        extends AbstractLettuceAccessor\n        implements AnomalyReportAccessor {\n\n    private final String jobIdName;\n    private final String timeName;\n    private final String frequencyName;\n    private final String emailIdReportName;\n\n    /**\n     * @param params store params\n     */\n    public LettuceAnomalyReportAccessor(StoreParams params) {\n        super(params);\n        this.jobIdName = params.get(DatabaseConstants.INDEX_REPORT_JOB_ID);\n        this.timeName = params.get(DatabaseConstants.INDEX_TIMESTAMP);\n        this.frequencyName = params.get(DatabaseConstants.INDEX_FREQUENCY);\n        this.emailIdReportName = params.get(DatabaseConstants.INDEX_EMAILID_REPORT);\n    }\n\n    /**\n     * @param report report to check ID\n     * @return whether the report has an assigned ID\n     */\n    protected static boolean isMissingId(AnomalyReport report) {\n        return report.getUniqueId() == null || report.getUniqueId().isEmpty();\n    }\n\n    @Override\n    public void putAnomalyReports(List<AnomalyReport> reports, List<String> emailIds) throws IOException {\n        log.info(\"Putting [{}] anomaly reports\", reports.size());\n        try (\n                RedisConnection<String> conn = connect();\n                RedisConnection<byte[]> binary = binary()\n        ) {\n            List<AnomalyReport> requireId = new ArrayList<>(reports.size());\n            List<AnomalyReport> ready = new ArrayList<>(reports.size());\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            for (AnomalyReport report : reports) {\n                if (isMissingId(report)) {\n                    requireId.add(report);\n                } else {\n                    ready.add(report);\n                }\n            }\n            if (!requireId.isEmpty()) {\n                log.info(\"Generating new IDs for [{}] reports\", requireId.size());\n                Integer[] newIds = newIds(requireId.size());\n                for (int i = 0; i < newIds.length; i++) {\n                    requireId.get(i).setUniqueId(newIds[i].toString());\n                }\n                ready.addAll(requireId);\n                requireId.clear();\n            }\n            List<RedisFuture> arrFutures = new ArrayList<>(ready.size() + 1);\n            RedisFuture[] saddFutures = new RedisFuture[ready.size() * (6 + 2 * emailIds.size())];\n            int i = 0;\n            long expirationTime = Constants.SECONDS_IN_DAY * (ready.get(0).getJobFrequency().equalsIgnoreCase(Constants.HOUR) ?\n                                                              Constants.REDIS_RETENTION_WEEKS_IN_DAYS : (ready.get(0).getJobFrequency().equalsIgnoreCase(Constants.MINUTE) ?\n                                                                                                        Constants.REDIS_RETENTION_ONE_DAY : Constants.REDIS_RETENTION_YEARS_IN_DAYS));\n            for (AnomalyReport report : ready) {\n                arrFutures.addAll(writeReport(bin, cmd, report, expirationTime, this));\n                saddFutures[i++] = cmd.sadd(index(jobIdName, report.getJobId()), report.getUniqueId());\n                saddFutures[i++] = cmd.expire(index(jobIdName, report.getJobId()), expirationTime);\n                saddFutures[i++] = cmd.sadd(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                saddFutures[i++] = cmd.expire(index(frequencyName, report.getJobFrequency()), expirationTime);\n                saddFutures[i++] = cmd.sadd(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                saddFutures[i++] = cmd.expire(index(timeName, report.getReportQueryEndTime()), expirationTime);\n                for (String emailId : emailIds) {\n                    saddFutures[i++] = cmd.sadd(index(emailIdReportName, emailId), report.getUniqueId());\n                    saddFutures[i++] = cmd.expire(index(emailIdReportName, emailId), expirationTime);\n                }\n            }\n            arrFutures.addAll(Lists.newArrayList(saddFutures));\n            cmd.flushCommands();\n            bin.flushCommands();\n            awaitRaw(arrFutures);\n            log.info(\"Successfully inserted reports\");\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForJob(String jobId, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] with frequency [{}]\", jobId, frequency);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobReportIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> freqReportIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobReportIds, freqReportIds);\n            Set<String> reportIds = jobReportIds.get();\n            reportIds.retainAll(freqReportIds.get());\n            return getAnomalyReports(reportIds, this);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForEmailId(String emailId) throws IOException {\n        log.info(\"Getting anomaly reports for Email ID [{}]\", emailId);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> emailReportIds = cmd.smembers(index(emailIdReportName, emailId));\n            cmd.flushCommands();\n            await(emailReportIds);\n            Set<String> reportIds = emailReportIds.get();\n            String[] rarr = new String[reportIds.size()];\n            int i = 0;\n            for (String s : reportIds) {\n                rarr[i] = s; i++;\n            }\n            if (i > 0) {\n                RedisFuture<Long> removedReports = cmd.srem(index(emailIdReportName, emailId), rarr);\n                cmd.flushCommands();\n                await(removedReports);\n            }\n            log.info(\"Removed {} anomaly reports to send it to {}\", rarr.length, emailId);\n            return getAnomalyReports(reportIds, this);\n        } catch (Exception e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public List<AnomalyReport> getAnomalyReportsForJobAtTime(String jobId, String time, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] frequency [{}] at time [{}]\", jobId, frequency, time);\n        try (RedisConnection<String> conn = connect()) {\n            AsyncCommands<String> cmd = conn.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobRepIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> jobTimeIds = cmd.smembers(index(timeName, time));\n            RedisFuture<Set<String>> jobFreqIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobRepIds, jobTimeIds, jobFreqIds);\n            Set<String> reportIds = jobRepIds.get();\n            reportIds.retainAll(jobTimeIds.get());\n            reportIds.retainAll(jobFreqIds.get());\n            return getAnomalyReports(reportIds, this);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public void deleteAnomalyReportsForJob(String jobId) throws IOException {\n        log.info(\"Deleting all anomaly reports for job [{}]\", jobId);\n        try (\n                RedisConnection<String> conn = connect();\n                RedisConnection<byte[]> binary = binary()\n        ) {\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            Set<String> reportIds = cmd.smembers(index(jobIdName, jobId)).get();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            List<AnomalyReport> reports = getAnomalyReports(reportIds, this);\n            RedisFuture[] futures = new RedisFuture[5 * reports.size() + 1];\n            int i = 0;\n            for (AnomalyReport report : reports) {\n                futures[i++] = cmd.srem(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                futures[i++] = cmd.del(key(report.getUniqueId()));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\")));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\")));\n            }\n            futures[i] = cmd.del(index(jobIdName, jobId));\n            cmd.flushCommands();\n            bin.flushCommands();\n            await(futures);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error while deleting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    @Override\n    public void deleteAnomalyReportsForJobAtTime(String jobId, String time, String frequency) throws IOException {\n        log.info(\"Getting anomaly reports for job [{}] frequency [{}] at time [{}] for deletion\", jobId, frequency, time);\n        try (\n            RedisConnection<String> conn = connect();\n            RedisConnection<byte[]> binary = binary()\n        ) {\n            // Get all report IDs\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            RedisFuture<Set<String>> jobRepIds = cmd.smembers(index(jobIdName, jobId));\n            RedisFuture<Set<String>> jobTimeIds = cmd.smembers(index(timeName, time));\n            RedisFuture<Set<String>> jobFreqIds = cmd.smembers(index(frequencyName, frequency));\n            cmd.flushCommands();\n            await(jobRepIds, jobTimeIds, jobFreqIds);\n            Set<String> reportIds = jobRepIds.get();\n            reportIds.retainAll(jobTimeIds.get());\n            reportIds.retainAll(jobFreqIds.get());\n            // Delete the reports\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            List<AnomalyReport> reports = getAnomalyReports(reportIds, this);\n            RedisFuture[] futures = new RedisFuture[6 * reports.size()];\n            int i = 0;\n            for (AnomalyReport report : reports) {\n                futures[i++] = cmd.srem(index(jobIdName, report.getJobId()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(timeName, report.getReportQueryEndTime()), report.getUniqueId());\n                futures[i++] = cmd.srem(index(frequencyName, report.getJobFrequency()), report.getUniqueId());\n                futures[i++] = cmd.del(key(report.getUniqueId()));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\")));\n                futures[i++] = bin.del(encode(key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\")));\n            }\n            cmd.flushCommands();\n            bin.flushCommands();\n            await(futures);\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error occurred while deleting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Write a report to the store, exacting the timestamps and\n     * encoding them as bytes.\n     *\n     * @param bin    binary commands\n     * @param cmd    string commands\n     * @param report report to write\n     * @param expirationTime expiration time of the key\n     * @param acc    accessor instance\n     * @return an array of futures that need to be awaited\n     */\n    @SuppressWarnings(\"unchecked\")\n    protected static List<RedisFuture> writeReport(\n            AsyncCommands<byte[]> bin,\n            AsyncCommands<String> cmd,\n            AnomalyReport report,\n            long expirationTime,\n            AbstractLettuceAccessor acc\n    ) {\n        List<int[]> timestamps = report.getAnomalyTimestampsHours();\n        Map<String, String> reportMap = acc.map(report);\n        reportMap.remove(DatabaseConstants.ANOMALY_TIMESTAMP);\n        byte[] keyStart = encode(acc.key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"start\"));\n        byte[] keyEnd = encode(acc.key(report.getUniqueId(), DatabaseConstants.ANOMALY_TIMESTAMP, \"end\"));\n        List<ScoredValue<byte[]>> valuesStart = new ArrayList<>(timestamps.size());\n        List<ScoredValue<byte[]>> valuesEnd = new ArrayList<>(timestamps.size());\n        for (int i = 0; i < timestamps.size(); i++) {\n            int[] timestamp = timestamps.get(i);\n            valuesStart.add(ScoredValue.fromNullable((double) i, NumberUtils.toBytesCompressed(timestamp[0])));\n            if (timestamp[1] != 0 && timestamp[1] != timestamp[0]) {\n                valuesEnd.add(ScoredValue.fromNullable((double) i, NumberUtils.toBytesCompressed(timestamp[1])));\n            }\n        }\n        List<RedisFuture> futures = new ArrayList<>(3);\n        futures.add(cmd.hmset(acc.key(report.getUniqueId()), reportMap));\n        futures.add(cmd.expire(acc.key(report.getUniqueId()), expirationTime));\n        log.info(\"Report \" + report.getUniqueId() + \" will expire in \" + expirationTime / Constants.SECONDS_IN_DAY + \" days\");\n        if (!valuesStart.isEmpty()) {\n            futures.add(bin.zadd(keyStart, valuesStart.toArray(new ScoredValue[valuesStart.size()])));\n            futures.add(bin.expire(keyStart, expirationTime));\n        }\n        if (!valuesEnd.isEmpty()) {\n            futures.add(bin.zadd(keyEnd, valuesEnd.toArray(new ScoredValue[valuesEnd.size()])));\n            futures.add(bin.expire(keyEnd, expirationTime));\n        }\n        return futures;\n    }\n\n    /**\n     * Get a list of anomaly reports corresponding\n     * to a set of report IDs.\n     *\n     * @param reportIds set of report IDs\n     * @param acc       accessor instance\n     * @return list of anomaly reports\n     * @throws IOException if an error occurs\n     */\n    protected static List<AnomalyReport> getAnomalyReports(\n            Set<String> reportIds,\n            AbstractLettuceAccessor acc\n    ) throws IOException {\n        try (\n                RedisConnection<String> conn = acc.connect();\n                RedisConnection<byte[]> binary = acc.binary()\n        ) {\n            List<RedisFuture<Map<String, String>>> values = new ArrayList<>(reportIds.size());\n            List<RedisFuture<List<ScoredValue<byte[]>>>> timeStart = new ArrayList<>(reportIds.size());\n            List<RedisFuture<List<ScoredValue<byte[]>>>> timeEnd = new ArrayList<>(reportIds.size());\n            AsyncCommands<String> cmd = conn.async();\n            AsyncCommands<byte[]> bin = binary.async();\n            cmd.setAutoFlushCommands(false);\n            bin.setAutoFlushCommands(false);\n            for (String id : reportIds) {\n                byte[] keyStart = encode(acc.key(id, DatabaseConstants.ANOMALY_TIMESTAMP, \"start\"));\n                byte[] keyEnd = encode(acc.key(id, DatabaseConstants.ANOMALY_TIMESTAMP, \"end\"));\n                values.add(cmd.hgetall(acc.key(id)));\n                timeStart.add(bin.zrangeWithScores(keyStart, 0, -1));\n                timeEnd.add(bin.zrangeWithScores(keyEnd, 0, -1));\n            }\n            cmd.flushCommands();\n            bin.flushCommands();\n            List<RedisFuture[]> combine = Lists.newArrayList(\n                    values.toArray(new RedisFuture[values.size()]),\n                    timeStart.toArray(new RedisFuture[timeStart.size()]),\n                    timeEnd.toArray(new RedisFuture[timeEnd.size()])\n            );\n            acc.awaitCollection(combine);\n            List<AnomalyReport> reports = new ArrayList<>(values.size());\n            for (int i = 0; i < values.size(); i++) {\n                AnomalyReport report = acc.unmap(AnomalyReport.class, values.get(i).get());\n                decodeAndSetTimestamp(report, timeStart.get(i).get(), timeEnd.get(i).get());\n                reports.add(report);\n            }\n            return reports;\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Error while getting anomaly reports!\", e);\n            throw new IOException(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Decode timestamps from lettuce responses.\n     *\n     * @param report    report to set timestamps\n     * @param startVals starting scored values\n     * @param endVals   ending scored values\n     */\n    protected static void decodeAndSetTimestamp(\n            AnomalyReport report,\n            List<ScoredValue<byte[]>> startVals,\n            List<ScoredValue<byte[]>> endVals\n    ) {\n        byte[][] startBytes = new byte[startVals.size()][];\n        byte[][] endBytes = new byte[startVals.size()][];\n        for (ScoredValue<byte[]> val : startVals) {\n            startBytes[(int) val.getScore()] = val.getValue();\n        }\n        for (ScoredValue<byte[]> val : endVals) {\n            endBytes[(int) val.getScore()] = val.getValue();\n        }\n        report.setAnomalyTimestampsFromBytes(startBytes, endBytes);\n    }\n\n}\n",
    "project": "sherlock",
    "libraryName": "lettuce-core",
    "libraryGroupID": "io.lettuce",
    "newVersion": "6.5.1.RELEASE",
    "previousVersion": "5.1.6.RELEASE",
    "breakingCommit": "7e1c7826b63cae9a472d707f4fb65b6add69b48e"
}